{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8468b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import openslide\n",
    "import numpy as np\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.filters import threshold_otsu\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.measure import points_in_poly\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9738ca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total \n",
      "normal vs tumor = 57942 vs 6886\n",
      "Train detail: \n",
      "normal vs tumor = 46943 vs 5567\n",
      "Valid detail: \n",
      "normal vs tumor = 5246 vs 589\n",
      "Test detail: \n",
      "normal vs tumor = 5753 vs 730\n"
     ]
    }
   ],
   "source": [
    "class WSIDataset(Dataset):\n",
    "    \"\"\"Generate dataset.\"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        self.all_data = pd.read_csv(filepath)\n",
    "        all_normal = self.all_data[self.all_data['label']=='Normal']\n",
    "        all_tumor = self.all_data[self.all_data['label']=='Tumor']\n",
    "        X = self.all_data['image'].tolist()\n",
    "        y = self.all_data['label'].tolist()\n",
    "        print('total ')\n",
    "        print('normal vs tumor = %d vs %d'%(len(all_normal), len(all_tumor)))\n",
    "        X_train, X_test, y_train, y_test = self.stage_split(X, y)\n",
    "    def stage_split(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)  # 0.25 x 0.8 = 0.2\n",
    "        print('Train detail: ')\n",
    "        train_normal, train_tumor = self.Obtain_detail(y_train)\n",
    "        print('normal vs tumor = %d vs %d'%(train_normal, train_tumor))\n",
    "        print('Valid detail: ')\n",
    "        train_normal, train_tumor = self.Obtain_detail(y_val)\n",
    "        print('normal vs tumor = %d vs %d'%(train_normal, train_tumor))\n",
    "        print('Test detail: ')\n",
    "        test_normal, test_tumor = self.Obtain_detail(y_test)\n",
    "        print('normal vs tumor = %d vs %d'%(test_normal, test_tumor))\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def Obtain_detail(self, y):\n",
    "        normal = tumor = 0\n",
    "        for i in y:\n",
    "            if i == 'Normal':\n",
    "                normal += 1\n",
    "            else:\n",
    "                tumor += 1\n",
    "        return normal, tumor\n",
    "\n",
    "wsi_data = WSIDataset('/home/congz3414050/HistoGCN/data/5X/all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d534405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Formatter(object):\n",
    "    \"\"\"\n",
    "    Format converter e.g. CAMELYON16 to internal json\n",
    "    \"\"\"\n",
    "    def camelyon16xml2json(self, inxml, outjson):\n",
    "        \"\"\"\n",
    "        Convert an annotation of camelyon16 xml format into a json format.\n",
    "        Arguments:\n",
    "            inxml: string, path to the input camelyon16 xml format\n",
    "            outjson: string, path to the output json format\n",
    "        \"\"\"\n",
    "        root = ET.parse(inxml).getroot()\n",
    "        annotations_tumor = \\\n",
    "            root.findall('./Annotations/Annotation[@PartOfGroup=\"Tumor\"]')\n",
    "        annotations_0 = \\\n",
    "            root.findall('./Annotations/Annotation[@PartOfGroup=\"_0\"]')\n",
    "        annotations_1 = \\\n",
    "            root.findall('./Annotations/Annotation[@PartOfGroup=\"_1\"]')\n",
    "        annotations_2 = \\\n",
    "            root.findall('./Annotations/Annotation[@PartOfGroup=\"_2\"]')\n",
    "\n",
    "        annotations_positive = \\\n",
    "            annotations_tumor + annotations_0 + annotations_1\n",
    "        annotations_negative = annotations_2\n",
    "\n",
    "\n",
    "        annotations_lunghp = \\\n",
    "            root.findall('./Annotations/Annotation[@PartOfGroup=\"None\"]')\n",
    "\n",
    "        annotations_cam17 = \\\n",
    "            root.findall('./Annotations/Annotation[@PartOfGroup=\"metastases\"]')\n",
    "\n",
    "        json_dict = {}\n",
    "        json_dict['positive'] = []\n",
    "        json_dict['negative'] = []\n",
    "\n",
    "        for annotation in annotations_positive:\n",
    "            X = list(map(lambda x: float(x.get('X')),\n",
    "                     annotation.findall('./Coordinates/Coordinate')))\n",
    "            Y = list(map(lambda x: float(x.get('Y')),\n",
    "                     annotation.findall('./Coordinates/Coordinate')))\n",
    "            vertices = np.round([X, Y]).astype(int).transpose().tolist()\n",
    "            name = annotation.attrib['Name']\n",
    "            json_dict['positive'].append({'name': name, 'vertices': vertices})\n",
    "\n",
    "        for annotation in annotations_negative:\n",
    "            X = list(map(lambda x: float(x.get('X')),\n",
    "                     annotation.findall('./Coordinates/Coordinate')))\n",
    "            Y = list(map(lambda x: float(x.get('Y')),\n",
    "                     annotation.findall('./Coordinates/Coordinate')))\n",
    "            vertices = np.round([X, Y]).astype(int).transpose().tolist()\n",
    "            name = annotation.attrib['Name']\n",
    "            json_dict['negative'].append({'name': name, 'vertices': vertices})\n",
    "\n",
    "        with open(outjson, 'w') as f:\n",
    "            json.dump(json_dict, f, indent=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13747f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68cc0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotations = '/home/congz3414050/HistoGCN/data/Original/test_annotation'\n",
    "json_path = '/home/congz3414050/HistoGCN/data/Original/test_annotation_json'\n",
    "\n",
    "for f in os.listdir(Annotations):\n",
    "    tumor_number = f.split('.')[0]\n",
    "    tumor_file = os.path.join(Annotations, f)\n",
    "    output_json = os.path.join(json_path, tumor_number + '.json')\n",
    "    _ = Formatter().camelyon16xml2json(tumor_file, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8444a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slide_Patch(object):\n",
    "    def __init__(self, dimension_level, slide_path, json_path, output_path, minRGB=50, patch_size=256, min_tissue=0.3):\n",
    "        self.dimension_level = dimension_level\n",
    "        self.slide_path = slide_path\n",
    "        self.tumor_number = os.path.basename(self.slide_path).split('.')[0]\n",
    "        self.json_path = json_path\n",
    "        print('Reading ', self.slide_path)\n",
    "        self.slide = openslide.OpenSlide(self.slide_path)\n",
    "        w, h = self.slide.level_dimensions[self.dimension_level]\n",
    "        self.mask_tumor = np.zeros((h, w))\n",
    "        self.scale = self.slide.level_downsamples[self.dimension_level]\n",
    "        print(self.scale)\n",
    "        self.img_RGB = np.transpose(np.array(self.slide.read_region((0, 0),\n",
    "                                                          self.dimension_level,\n",
    "                                                          (w,h)).convert('RGB')), axes=[1, 0, 2])\n",
    "        self.img_hsv = cv2.cvtColor(self.img_RGB, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        self.outpath = output_path\n",
    "        self.minRGB = minRGB\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.out_path = os.path.join(self.outpath, 'test_' + str(self.tumor_number))\n",
    "        if not os.path.exists(self.out_path):\n",
    "            os.mkdir(self.out_path)\n",
    "\n",
    "        self.out_path_normal = os.path.join(self.out_path, 'Normal')\n",
    "        if not os.path.exists(self.out_path_normal):\n",
    "            os.mkdir(self.out_path_normal)\n",
    "\n",
    "        self.out_path_tumor = os.path.join(self.out_path, 'Tumor')\n",
    "        if not os.path.exists(self.out_path_tumor):\n",
    "            os.mkdir(self.out_path_tumor)\n",
    "\n",
    "        self.min_tumor_number = self.patch_size * self.patch_size * min_tissue\n",
    "        self.thresh_cal()\n",
    "        self.slide.close()\n",
    "\n",
    "    def thresh_cal(self):\n",
    "        print('==> calculate threshold')\n",
    "        self.color_thresh_R = threshold_otsu(self.img_RGB[:, :, 0])\n",
    "        self.color_thresh_G = threshold_otsu(self.img_RGB[:, :, 1])\n",
    "        self.color_thresh_B = threshold_otsu(self.img_RGB[:, :, 2])\n",
    "        self.color_thresh_H = threshold_otsu(self.img_hsv[:, :, 1])\n",
    "        print('==> threshold done')\n",
    "\n",
    "    def _tissue_mask(self, img=False, check=False):\n",
    "        background_R = self.img_RGB[:, :, 0] > self.color_thresh_R\n",
    "        background_G = self.img_RGB[:, :, 1] > self.color_thresh_G\n",
    "        background_B = self.img_RGB[:, :, 2] > self.color_thresh_B\n",
    "        tissue_RGB = np.logical_not(background_R & background_G & background_B)\n",
    "        tissue_S = self.img_hsv[:, :, 1] > self.color_thresh_H\n",
    "        min_R =  self.img_RGB[:, :, 0] > self.minRGB\n",
    "        min_G =  self.img_RGB[:, :, 1] > self.minRGB\n",
    "        min_B =  self.img_RGB[:, :, 2] > self.minRGB\n",
    "        tissue_mask = tissue_S & tissue_RGB & min_R & min_G & min_B  ###############tissue mask\n",
    "#         tissue_mask = tissue_RGB & min_R & min_G & min_B###############tissue mask\n",
    "\n",
    "        return tissue_mask  # levl4\n",
    "\n",
    "    def _tumor_mask(self):\n",
    "        tumor_json = os.path.basename(self.slide_path).split('.')[0] + '.json'\n",
    "        tumor_json = os.path.join(self.json_path, tumor_json)\n",
    "\n",
    "        if not os.path.exists(tumor_json):\n",
    "            print('not exist')\n",
    "            tumor_mask = np.array([])\n",
    "        else:\n",
    "            with open(tumor_json) as f:\n",
    "                dicts = json.load(f)\n",
    "            tumor_polygons = dicts['positive']  # dicts['mask']#\n",
    "\n",
    "            for tumor_polygon in tumor_polygons:\n",
    "                # plot a polygon\n",
    "                name = tumor_polygon[\"name\"]\n",
    "                vertices = np.array(tumor_polygon[\"vertices\"]) / self.scale\n",
    "                vertices = vertices.astype(np.int32)\n",
    "                cv2.fillPoly(self.mask_tumor, [vertices], (255))\n",
    "\n",
    "            self.mask_tumor = self.mask_tumor[:] > 127\n",
    "            tumor_mask = np.transpose(self.mask_tumor)\n",
    "\n",
    "        return tumor_mask  # level4\n",
    "\n",
    "    def mask(self, plot=True):\n",
    "        tissue_mask = self._tissue_mask()\n",
    "        tumor_mask = self._tumor_mask()\n",
    "        if tumor_mask.shape[0] == 0:\n",
    "            normal_mask, questionable_mask = tissue_mask, np.zeros((tissue_mask.shape[0], tissue_mask.shape[1]))\n",
    "        else:\n",
    "            normal_mask, questionable_mask = tissue_mask & (~ tumor_mask), tissue_mask & (tumor_mask)\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(0, figsize=(18, 18))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(normal_mask)\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(questionable_mask)\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(self.img_RGB)\n",
    "            plt.show()\n",
    "        return normal_mask, questionable_mask, self.img_RGB  # level4\n",
    "\n",
    "    def slide_to_img(self, item_list):\n",
    "        img, label, coor = item_list\n",
    "\n",
    "        image = Image.fromarray(img)\n",
    "        if label == 1:\n",
    "            img_save_path = os.path.join(self.out_path_normal, 'image')\n",
    "        else:\n",
    "            img_save_path = os.path.join(self.out_path_tumor, 'image')\n",
    "        if not os.path.exists(img_save_path):\n",
    "            os.mkdir(img_save_path)\n",
    "        image.save(img_save_path + '/' + str(coor) + '.png')\n",
    "        # print('==> image saved ',img_save_path)\n",
    "        return [img_save_path + '/' + str(coor) + '.png', str(label)]\n",
    "\n",
    "    def obtain_all_patchpts(self):\n",
    "        '''\n",
    "        random sampling positive and negative samples\n",
    "        '''\n",
    "        normal, questionable_mask, rgb = self.mask(plot=True)  # level4\n",
    "        # normal\n",
    "        X_idcs_n, Y_idcs_n = np.where(normal)\n",
    "        centre_points_normal = np.stack(np.vstack((X_idcs_n.T, Y_idcs_n.T)), axis=1)\n",
    "        mask_name = [1, 0]\n",
    "        name = np.full((centre_points_normal.shape[0], 2), mask_name)\n",
    "        normal_center_points = np.hstack((centre_points_normal, name))\n",
    "        # tumor\n",
    "        X_idcs_t, Y_idcs_t = np.where(questionable_mask)\n",
    "        centre_points_tumor = np.stack(np.vstack((X_idcs_t.T, Y_idcs_t.T)), axis=1)\n",
    "        mask_name = [0, 1]\n",
    "        name = np.full((centre_points_tumor.shape[0], 2), mask_name)\n",
    "        tumor_center_points = np.hstack((centre_points_tumor, name))\n",
    "        return normal_center_points, tumor_center_points, normal, questionable_mask, rgb  ###########\n",
    "\n",
    "    def is_tumor(self, x, y, size, tumor_mask):\n",
    "        if y + size > tumor_mask.shape[0] or x + size > tumor_mask.shape[1]:\n",
    "            return False\n",
    "        select_tumor_mask = tumor_mask[y:y + size, x:x + size]\n",
    "        include_tumor = np.count_nonzero(select_tumor_mask)\n",
    "        return True if include_tumor / (select_tumor_mask.shape[0] * select_tumor_mask.shape[1]) > 0.001 else False\n",
    "\n",
    "    def is_normal(self, x, y, size, normal_mask):\n",
    "        if y + size > normal_mask.shape[0] or x + size > normal_mask.shape[1]:\n",
    "            return False\n",
    "\n",
    "        select_normal_mask = normal_mask[y:y + size, x:x + size]\n",
    "        include_normal = np.count_nonzero(select_normal_mask)\n",
    "        return True if include_normal / (select_normal_mask.shape[0] * select_normal_mask.shape[1]) > 0.1 else False\n",
    "\n",
    "    def iter_over_slide(self, x_min, y_min, x_max, y_max, step, level, tm, nm):\n",
    "        all_sample = []\n",
    "        rects = []\n",
    "\n",
    "        img_save_path_normal = os.path.join(self.out_path_normal, 'image')\n",
    "        img_save_path_tumor = os.path.join(self.out_path_tumor, 'image')\n",
    "\n",
    "        if not os.path.exists(img_save_path_normal):\n",
    "            os.mkdir(img_save_path_normal)\n",
    "        if not os.path.exists(img_save_path_tumor):\n",
    "            os.mkdir(img_save_path_tumor)\n",
    "\n",
    "        tumor_count = 0\n",
    "        normal_count = 0\n",
    "        # print(x_min, x_max,y_min, y_max, )\n",
    "        for y in range(y_min, y_max, step):\n",
    "            for x in range(x_min, x_max, step):\n",
    "\n",
    "                if self.is_tumor(x, y, step, tm):  # Tumor\n",
    "                    select_sample = self.img_RGB[y:y + step, x:x + step]\n",
    "                    image = Image.fromarray(select_sample)\n",
    "                    image_pth = os.path.join(img_save_path_tumor, str(x) + '_' + str(y) + '.png')\n",
    "                    image.save(image_pth)\n",
    "                    mask = tm[y:y + step, x:x + step]\n",
    "                    mask = Image.fromarray(mask)\n",
    "                    out_tumor_mask_pth = os.path.join(self.out_path_tumor, 'mask')\n",
    "                    if not os.path.exists(out_tumor_mask_pth):\n",
    "                        os.mkdir(out_tumor_mask_pth)\n",
    "                    mask.save(os.path.join(out_tumor_mask_pth, str(x) + '_' + str(y) + '.png'))\n",
    "                    rects.append(\n",
    "                        patches.Rectangle((x, y), self.patch_size, self.patch_size, edgecolor='r', facecolor=\"none\"))\n",
    "                    tumor_count += 1\n",
    "                elif self.is_normal(x, y, step, nm):  # Normal\n",
    "                    select_sample = self.img_RGB[y:y + step, x:x + step]\n",
    "                    image = Image.fromarray(select_sample)\n",
    "                    image_pth = os.path.join(img_save_path_normal, str(x) + '_' + str(y) + '.png')\n",
    "                    image.save(image_pth)\n",
    "                    rects.append(\n",
    "                        patches.Rectangle((x, y), self.patch_size, self.patch_size, edgecolor='b', facecolor=\"none\"))\n",
    "                    normal_count += 1\n",
    "        print('=> tumor : ', tumor_count)\n",
    "        print('=> normal : ', normal_count)\n",
    "        return rects\n",
    "\n",
    "    def patch_gen(self):\n",
    "        normal_coord, tumor_coord, normal_mask, tumor_mask, RGB_image = self.obtain_all_patchpts()\n",
    "        normal_coord = normal_coord[:, 0:2]\n",
    "        rects = self.iter_over_slide(np.min(normal_coord[:, 1]), np.min(normal_coord[:, 0]), \\\n",
    "                                     np.max(normal_coord[:, 1]), np.max(normal_coord[:, 0]), \\\n",
    "                                     self.patch_size, self.dimension_level, tumor_mask, normal_mask)\n",
    "\n",
    "        figure, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "        ax.imshow(RGB_image)\n",
    "        ax.add_patch(patches.Rectangle((np.min(normal_coord[:, 1]), np.min(normal_coord[:, 0])),\n",
    "                                       np.max(normal_coord[:, 1]) - np.min(normal_coord[:, 1]),\n",
    "                                       np.max(normal_coord[:, 0]) - np.min(normal_coord[:, 0]), edgecolor='b',\n",
    "                                       facecolor=\"none\"))\n",
    "        for i in rects:\n",
    "            ax.add_patch(i)\n",
    "        thumbnail_pth = os.path.join(self.outpath, 'thumbnails')\n",
    "        if not os.path.exists(thumbnail_pth):\n",
    "            os.mkdir(thumbnail_pth)\n",
    "        plot_out = os.path.join(thumbnail_pth, '%s.png'%self.tumor_number)\n",
    "        plt.savefig(plot_out)\n",
    "        plt.show()\n",
    "        print('outpath ',self.outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d1b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': [{'name': 'Annotation 0', 'vertices': [[16695, 158590], [16604, 158707], [16501, 158817], [16582, 158942], [16714, 159011], [16849, 159070], [16996, 159095], [17146, 159095], [17303, 159095], [17454, 159095], [17593, 159033], [17681, 158909], [17578, 158802], [17364, 158823], [17368, 158663], [17146, 158645], [16996, 158703], [16860, 158645]]}], 'negative': []}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/congz3414050/HistoGCN/data/Original/test_annotation_json/test_097.json') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "# Output: {'name': 'Bob', 'languages': ['English', 'Fench']}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4f3010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  /home/congz3414050/HistoGCN/data/Original/test_image/test_097.tif\n",
      "8.0\n",
      "==> calculate threshold\n",
      "==> threshold done\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_946677/2152936229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpatch_generator_tumor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlide_Patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslide_pth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpatch_generator_tumor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_946677/3253870974.py\u001b[0m in \u001b[0;36mpatch_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpatch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mnormal_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtumor_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtumor_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRGB_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobtain_all_patchpts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mnormal_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_coord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         rects = self.iter_over_slide(np.min(normal_coord[:, 1]), np.min(normal_coord[:, 0]), \\\n",
      "\u001b[0;32m/tmp/ipykernel_946677/3253870974.py\u001b[0m in \u001b[0;36mobtain_all_patchpts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mrandom\u001b[0m \u001b[0msampling\u001b[0m \u001b[0mpositive\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         '''\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mnormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestionable_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# level4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mX_idcs_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_idcs_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_946677/3253870974.py\u001b[0m in \u001b[0;36mmask\u001b[0;34m(self, plot)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mtissue_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tissue_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtumor_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tumor_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtumor_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mnormal_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestionable_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtissue_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtissue_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtissue_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_946677/3253870974.py\u001b[0m in \u001b[0;36m_tumor_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtumor_json\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mdicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mtumor_polygons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# dicts['mask']#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtumor_polygon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtumor_polygons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'positive'"
     ]
    }
   ],
   "source": [
    "rt = '/home/congz3414050/HistoGCN/data/Original/test_image'\n",
    "out = '/home/congz3414050/HistoGCN/data/5X/Tumor/Train'\n",
    "annotation_path = '/home/congz3414050/HistoGCN/data/Original/test_annotation_json'\n",
    "import time\n",
    "# finished = ['tumor_102.tif','tumor_001.tif','tumor_088.tif']#,'patient_004','patient_009','patient_015','patient_016','patient_018']\n",
    "for i in os.listdir(rt):\n",
    "    tumor_name = i.split('.tif')[0]\n",
    "#     if tumor_name not in finished:\n",
    "    if i.endswith('.tif'):\n",
    "        slide_pth = os.path.join(rt, i)\n",
    "\n",
    "        patch_generator_tumor = Slide_Patch(3, slide_pth, annotation_path, out, patch_size=256)\n",
    "        patch_generator_tumor.patch_gen()\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb76b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# root = '/home/congz3414050/HistoGCN/data/5X/Tumor_768/Train'\n",
    "# out = '/home/congz3414050/HistoGCN/data/5X/Tumor_768/csvs'\n",
    "# out_all = '/home/congz3414050/HistoGCN/data/5X/Tumor_768/'\n",
    "\n",
    "# def path2csv(root, out):\n",
    "#     count = 0\n",
    "#     for tumors in os.listdir(root):\n",
    "#         if tumors == 'thumbnails':\n",
    "#             continue\n",
    "#         content = {'node':[], 'coord':[], 'label':[], 'id':[], 'slide':[], 'mask':[]}\n",
    "#         tumor_pth = os.path.join(root, tumors)\n",
    "#         ids = 0\n",
    "\n",
    "#         for sub_root in os.listdir(tumor_pth):\n",
    "#             sub_root_pth = os.path.join(tumor_pth, sub_root, 'image')\n",
    "#             if sub_root == 'Tumor':\n",
    "#                 sub_root_mask_pth = os.path.join(tumor_pth, sub_root, 'mask')\n",
    "#             else:\n",
    "#                 sub_root_mask_pth = False\n",
    "#             if len(os.listdir(sub_root_pth)) == 0:\n",
    "#                 break\n",
    "#             for node in os.listdir(sub_root_pth):\n",
    "#                 node_pth = os.path.join(sub_root_pth, node)\n",
    "#                 mask_pth = os.path.join(sub_root_mask_pth, node) if sub_root_mask_pth else 'Nothing'\n",
    "#                 node_coor_combine = node.split('.png')[0]\n",
    "#                 node_label = sub_root\n",
    "#                 content['node'].append(node_pth)\n",
    "#                 content['coord'].append(node_coor_combine)\n",
    "#                 content['label'].append(node_label)\n",
    "#                 content['id'].append(ids)\n",
    "#                 content['slide'].append(tumors)\n",
    "#                 content['mask'].append(mask_pth)\n",
    "#                 ids += 1\n",
    "#         count += 1\n",
    "#             #     print(content)\n",
    "#             #     break\n",
    "#             # break\n",
    "        \n",
    "#         if len(content['node'])!=0:\n",
    "#             out_csv_pth = os.path.join(out, '%s.csv'%tumors)\n",
    "#             df = pd.DataFrame.from_dict(content)\n",
    "#             df.to_csv(out_csv_pth, index=False)\n",
    "\n",
    "\n",
    "#     print('total %d csvs'%count)\n",
    "\n",
    "# def obtain_class(root):\n",
    "#     out_pth = root\n",
    "#     root = root + 'csvs'\n",
    "#     content = {'image':[],'label':[],'slide':[], 'mask':[]}\n",
    "#     # prefix = 'F:\\BaiduNetdiskDownload\\CAMELYON16\\GCN\\data'\n",
    "#     for tumor_csv in os.listdir(root):\n",
    "#         csv_path = os.path.join(root, tumor_csv)\n",
    "#         df = pd.read_csv(csv_path)\n",
    "\n",
    "#         content['image'] += df['node'].tolist()\n",
    "#         content['label'] += df['label'].tolist()\n",
    "#         content['slide'] += df['slide'].tolist()\n",
    "#         content['mask'] += df['mask'].tolist()\n",
    "\n",
    "#     out_csv_pth = os.path.join(out_pth, 'all_data.csv')\n",
    "#     df = pd.DataFrame.from_dict(content)\n",
    "#     df.to_csv(out_csv_pth, index=False)\n",
    "#     print('total ',len(df))\n",
    "#     print(out_csv_pth)\n",
    "# # \n",
    "# path2csv(root, out)\n",
    "# obtain_class(out_all)\n",
    "# # df = pd.read_csv(r'F:\\BaiduNetdiskDownload\\CAMELYON16\\GCN\\data\\5X\\csvs\\all_data.csv')\n",
    "# # df_normal = df[df['label']=='Normal']\n",
    "# # df_tumor = df[df['label']=='Tumor']\n",
    "# # print(len(df_normal),len(df_tumor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c1525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polygon(object):\n",
    "    \"\"\"\n",
    "    Polygon represented as [N, 2] array of vertices\n",
    "    \"\"\"\n",
    "    def __init__(self, name, vertices):\n",
    "        \"\"\"\n",
    "        Initialize the polygon.\n",
    "        Arguments:\n",
    "            name: string, name of the polygon\n",
    "            vertices: [N, 2] 2D numpy array of int\n",
    "        \"\"\"\n",
    "        self._name = name\n",
    "        self._vertices = vertices\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._name\n",
    "\n",
    "    def inside(self, coord):\n",
    "        \"\"\"\n",
    "        Determine if a given coordinate is inside the polygon or not.\n",
    "        Arguments:\n",
    "            coord: 2 element tuple of int, e.g. (x, y)\n",
    "        Returns:\n",
    "            bool, if the coord is inside the polygon.\n",
    "        \"\"\"\n",
    "        return points_in_poly([coord], self._vertices)[0]\n",
    "\n",
    "    def vertices(self):\n",
    "\n",
    "        return np.array(self._vertices)\n",
    "\n",
    "\n",
    "class Annotation(object):\n",
    "    \"\"\"\n",
    "    Annotation about the regions within WSI in terms of vertices of polygons.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=8.0):\n",
    "        self._json_path = ''\n",
    "        self._polygons_positive = []\n",
    "        self._polygons_negative = []\n",
    "        self.scale = scale\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._json_path\n",
    "\n",
    "    def from_json(self, json_path, ):\n",
    "        \"\"\"\n",
    "        Initialize the annotation from a json file.\n",
    "        Arguments:\n",
    "            json_path: string, path to the json annotation.\n",
    "        \"\"\"\n",
    "        self._json_path = json_path\n",
    "        with open(json_path) as f:\n",
    "            annotations_json = json.load(f)\n",
    "\n",
    "        for annotation in annotations_json['positive']:\n",
    "            name = annotation['name']\n",
    "            vertices = np.array(annotation[\"vertices\"]) / self.scale\n",
    "            vertices = vertices.astype(np.int32)\n",
    "            polygon = Polygon(name, vertices)\n",
    "            self._polygons_positive.append(polygon)\n",
    "\n",
    "        for annotation in annotations_json['negative']:\n",
    "            name = annotation['name']\n",
    "            vertices = np.array(annotation[\"vertices\"]) / self.scale\n",
    "            vertices = vertices.astype(np.int32)\n",
    "            polygon = Polygon(name, vertices)\n",
    "            self._polygons_negative.append(polygon)\n",
    "\n",
    "    def inside_polygons(self, coord, is_positive):\n",
    "        \"\"\"\n",
    "        Determine if a given coordinate is inside the positive/negative\n",
    "        polygons of the annotation.\n",
    "        Arguments:\n",
    "            coord: 2 element tuple of int, e.g. (x, y)\n",
    "            is_positive: bool, inside positive or negative polygons.\n",
    "        Returns:\n",
    "            bool, if the coord is inside the positive/negative polygons of the\n",
    "            annotation.\n",
    "        \"\"\"\n",
    "        if is_positive:\n",
    "            polygons = copy.deepcopy(self._polygons_positive)\n",
    "        else:\n",
    "            polygons = copy.deepcopy(self._polygons_negative)\n",
    "\n",
    "        for polygon in polygons:\n",
    "            if polygon.inside(coord):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def polygon_vertices(self, is_positive):\n",
    "        \"\"\"\n",
    "        Return the polygon represented as [N, 2] array of vertices\n",
    "        Arguments:\n",
    "            is_positive: bool, return positive or negative polygons.\n",
    "        Returns:\n",
    "            [N, 2] 2D array of int\n",
    "        \"\"\"\n",
    "        if is_positive:\n",
    "            return list(map(lambda x: x.vertices(), self._polygons_positive))\n",
    "        else:\n",
    "            return list(map(lambda x: x.vertices(), self._polygons_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a6e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Data producer that generate a square grid, e.g. 3x3, of patches and their\n",
    "    corresponding labels from pre-sampled images.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, json_path, img_size, patch_size,\n",
    "                 crop_size=224, normalize=True):\n",
    "        \"\"\"\n",
    "        Initialize the data producer.\n",
    "        Arguments:\n",
    "            data_path: string, path to pre-sampled images using patch_gen.py\n",
    "            img_size: int, size of pre-sampled images, e.g. 768\n",
    "            patch_size: int, size of the patch, e.g. 256\n",
    "            crop_size: int, size of the final crop that is feed into a CNN,\n",
    "                e.g. 224 for ResNet\n",
    "            normalize: bool, if normalize the [0, 255] pixel values to [-1, 1],\n",
    "                mostly False for debuging purpose\n",
    "        \"\"\"\n",
    "        self._df = data_path\n",
    "        self._json_path = json_path\n",
    "        self._img_size = img_size\n",
    "        self._patch_size = patch_size\n",
    "        self._crop_size = crop_size\n",
    "        self._normalize = normalize\n",
    "        self._color_jitter = transforms.ColorJitter(64.0/255, 0.75, 0.25, 0.04)\n",
    "        self._preprocess()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        if self._img_size % self._patch_size != 0:\n",
    "            raise Exception('Image size / patch size != 0 : {} / {}'.\n",
    "                            format(self._img_size, self._patch_size))\n",
    "\n",
    "        self._patch_per_side = self._img_size // self._patch_size\n",
    "        self._grid_size = self._patch_per_side * self._patch_per_side\n",
    "\n",
    "        self._pids = list(map(lambda x: x.strip('.json'),\n",
    "                              os.listdir(self._json_path)))\n",
    "\n",
    "#         self._annotations = {}\n",
    "#         for pid in self._pids:\n",
    "#             pid_json_path = os.path.join(self._json_path, pid + '.json')\n",
    "#             anno = Annotation()\n",
    "#             anno.from_json(pid_json_path)\n",
    "#             self._annotations[pid] = anno\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_pth = self._df.iloc[idx, 0]\n",
    "        mask_pth = self._df.iloc[idx, 3]\n",
    "\n",
    "        slide_name = self._df.iloc[idx, 2]\n",
    "        image_name = image_pth.split('/')[-1].split('.png')[0].split('_')\n",
    "        x_top_left, y_top_left = 0,0 #int(image_name[0]), int(image_name[1])\n",
    "        patch_label = self._df.iloc[idx, 1]\n",
    "\n",
    "        # the grid of labels for each patch\n",
    "        label_grid = np.zeros((self._patch_per_side, self._patch_per_side),\n",
    "                              dtype=np.float32)\n",
    "        if mask_pth != 'Nothing':\n",
    "            mask_np = cv2.imread(mask_pth)\n",
    "            for x_i in range(self._patch_per_side):\n",
    "                x_t = x_top_left + self._patch_size * x_i\n",
    "                for y_i in range(self._patch_per_side):\n",
    "                    y_t = y_top_left + self._patch_size * y_i\n",
    "                    select_tumor_mask = mask_np[x_t: x_t + self._patch_size, y_t: y_t + self._patch_size]\n",
    "                    include_tumor = np.count_nonzero(select_tumor_mask)\n",
    "\n",
    "                    if include_tumor / (mask_np.shape[0] * mask_np.shape[1]) > 0.001:\n",
    "                        label = 1\n",
    "                    else:\n",
    "                        label = 0\n",
    "\n",
    "                    label_grid[y_i, x_i] = label\n",
    "     \n",
    "\n",
    "        img = Image.open(image_pth)\n",
    "\n",
    "        # color jitter\n",
    "        img = self._color_jitter(img)\n",
    "\n",
    "        # use left_right flip\n",
    "        if np.random.rand() > 0.5:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            label_grid = np.fliplr(label_grid)\n",
    "\n",
    "        # use rotate\n",
    "        num_rotate = np.random.randint(0, 4)\n",
    "        img = img.rotate(90 * num_rotate)\n",
    "        label_grid = np.rot90(label_grid, num_rotate)\n",
    "\n",
    "        # PIL image:   H x W x C\n",
    "        # torch image: C X H X W\n",
    "        img = np.array(img, dtype=np.float32).transpose((2, 0, 1))\n",
    "\n",
    "        if self._normalize:\n",
    "            img = (img - 128.0)/128.0\n",
    "\n",
    "        # flatten the square grid\n",
    "        img_flat = np.zeros(\n",
    "            (self._grid_size, 3, self._crop_size, self._crop_size),\n",
    "            dtype=np.float32)\n",
    "        label_flat = np.zeros(self._grid_size, dtype=np.float32)\n",
    "\n",
    "        idx = 0\n",
    "        for x_idx in range(self._patch_per_side):\n",
    "            for y_idx in range(self._patch_per_side):\n",
    "                # center crop each patch\n",
    "                x_start = int(\n",
    "                    (x_idx + 0.5) * self._patch_size - self._crop_size / 2)\n",
    "                x_end = x_start + self._crop_size\n",
    "                y_start = int(\n",
    "                    (y_idx + 0.5) * self._patch_size - self._crop_size / 2)\n",
    "                y_end = y_start + self._crop_size\n",
    "                img_flat[idx] = img[:, x_start:x_end, y_start:y_end]\n",
    "                label_flat[idx] = label_grid[x_idx, y_idx]\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "        return (img_flat, label_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ec9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSIDataset(Dataset):\n",
    "    \"\"\"Generate dataset.\"\"\"\n",
    "    def __init__(self, filepath, annotation_pth):\n",
    "        self.all_data = pd.read_csv(filepath)\n",
    "        self.annotation = annotation_pth\n",
    "        all_normal, all_tumor = self.Obtain_detail(self.all_data['label'].tolist())\n",
    "        print('total: ', all_normal, all_tumor)\n",
    "        self.train_data = self.all_data.sample(frac=0.8, replace=False, random_state=200) #random state is a seed value\n",
    "        self.test_data = self.all_data.drop(self.train_data.index)\n",
    "        train_normal, train_tumor = self.Obtain_detail(self.train_data['label'].tolist())\n",
    "        print('train: ', train_normal, train_tumor)\n",
    "        test_normal, test_tumor = self.Obtain_detail(self.test_data['label'].tolist())\n",
    "        print('test: ', test_normal, test_tumor)\n",
    "\n",
    "    def Obtain_detail(self, y):\n",
    "        normal = tumor = 0\n",
    "        for i in y:\n",
    "            if i == 'Normal':\n",
    "                normal += 1\n",
    "            else:\n",
    "                tumor += 1\n",
    "        return normal, tumor\n",
    "\n",
    "    def Obtain_dataset(self, stage):\n",
    "        if stage == 'Train':\n",
    "            self.dataset = GridImageDataset(self.train_data, self.annotation, 768, 256)\n",
    "        elif stage == 'Test':\n",
    "            self.dataset = GridImageDataset(self.test_data, self.annotation, 768, 256)\n",
    "        return self.dataset\n",
    "\n",
    "    def Obtain_loader(self, stage, batch_size):\n",
    "        ds = self.Obtain_dataset(stage)\n",
    "        self.loader = DataLoader(ds,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=1,\n",
    "                                 drop_last=True)\n",
    "        return self.loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fa65933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CRF(nn.Module):\n",
    "    def __init__(self, num_nodes, iteration=10):\n",
    "        \"\"\"Initialize the CRF module\n",
    "        Args:\n",
    "            num_nodes: int, number of nodes/patches within the fully CRF\n",
    "            iteration: int, number of mean field iterations, e.g. 10\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.iteration = iteration\n",
    "        self.W = nn.Parameter(torch.zeros(1, num_nodes, num_nodes))\n",
    "\n",
    "    def forward(self, feats, logits):\n",
    "        \"\"\"Performing the CRF. Algorithm details is explained below:\n",
    "        Within the paper, I formulate the CRF distribution using negative\n",
    "        energy and cost, e.g. cosine distance, to derive pairwise potentials\n",
    "        following the convention in energy based models. But for implementation\n",
    "        simplicity, I use reward, e.g. cosine similarity to derive pairwise\n",
    "        potentials. So now, pairwise potentials would encourage high reward for\n",
    "        assigning (y_i, y_j) with the same label if (x_i, x_j) are similar, as\n",
    "        measured by cosine similarity, pairwise_sim. For\n",
    "        pairwise_potential_E = torch.sum(\n",
    "            probs * pairwise_potential - (1 - probs) * pairwise_potential,\n",
    "            dim=2, keepdim=True\n",
    "        )\n",
    "        This is taking the expectation of pairwise potentials using the current\n",
    "        marginal distribution of each patch being tumor, i.e. probs. There are\n",
    "        four cases to consider when taking the expectation between (i, j):\n",
    "        1. i=T,j=T; 2. i=N,j=T; 3. i=T,j=N; 4. i=N,j=N\n",
    "        probs is the marginal distribution of each i being tumor, therefore\n",
    "        logits > 0 means tumor and logits < 0 means normal. Given this, the\n",
    "        full expectation equation should be:\n",
    "        [probs * +pairwise_potential] + [(1 - probs) * +pairwise_potential] +\n",
    "                    case 1                            case 2\n",
    "        [probs * -pairwise_potential] + [(1 - probs) * -pairwise_potential]\n",
    "                    case 3                            case 4\n",
    "        positive sign rewards logits to be more tumor and negative sign rewards\n",
    "        logits to be more normal. But because of label compatibility, i.e. the\n",
    "        indicator function within equation 3 in the paper, case 2 and case 3\n",
    "        are dropped, which ends up being:\n",
    "        probs * pairwise_potential - (1 - probs) * pairwise_potential\n",
    "        In high level speaking, if (i, j) embedding are different, then\n",
    "        pairwise_potential, as computed as cosine similarity, would approach 0,\n",
    "        which then as no affect anyway. if (i, j) embedding are similar, then\n",
    "        pairwise_potential would be a positive reward. In this case,\n",
    "        if probs -> 1, then pairwise_potential promotes tumor probability;\n",
    "        if probs -> 0, then -pairwise_potential promotes normal probability.\n",
    "        Args:\n",
    "            feats: 3D tensor with the shape of\n",
    "            [batch_size, num_nodes, embedding_size], where num_nodes is the\n",
    "            number of patches within a grid, e.g. 9 for a 3x3 grid;\n",
    "            embedding_size is the size of extracted feature representation for\n",
    "            each patch from ResNet, e.g. 512\n",
    "            logits: 3D tensor with shape of [batch_size, num_nodes, 1], the\n",
    "            logit of each patch within the grid being tumor before CRF\n",
    "        Returns:\n",
    "            logits: 3D tensor with shape of [batch_size, num_nodes, 1], the\n",
    "            logit of each patch within the grid being tumor after CRF\n",
    "        \"\"\"\n",
    "        feats_norm = torch.norm(feats, p=2, dim=2, keepdim=True)\n",
    "        pairwise_norm = torch.bmm(feats_norm,\n",
    "                                  torch.transpose(feats_norm, 1, 2))\n",
    "        pairwise_dot = torch.bmm(feats, torch.transpose(feats, 1, 2))\n",
    "        # cosine similarity between feats\n",
    "        pairwise_sim = pairwise_dot / pairwise_norm\n",
    "        # symmetric constraint for CRF weights\n",
    "        W_sym = (self.W + torch.transpose(self.W, 1, 2)) / 2\n",
    "        pairwise_potential = pairwise_sim * W_sym\n",
    "        unary_potential = logits.clone()\n",
    "\n",
    "        for i in range(self.iteration):\n",
    "            # current Q after normalizing the logits\n",
    "            probs = torch.transpose(logits.sigmoid(), 1, 2)\n",
    "            # taking expectation of pairwise_potential using current Q\n",
    "            pairwise_potential_E = torch.sum(\n",
    "                probs * pairwise_potential - (1 - probs) * pairwise_potential,\n",
    "                dim=2, keepdim=True)\n",
    "            logits = unary_potential + pairwise_potential_E\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "180c1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNetCRF(nn.Module):\n",
    "\n",
    "#     def __init__(self, num_classes=1, num_nodes=1, use_crf=True):\n",
    "#         \"\"\"Constructs a ResNet model.\n",
    "#         Args:\n",
    "#             num_classes: int, since we are doing binary classification\n",
    "#                 (tumor vs normal), num_classes is set to 1 and sigmoid instead\n",
    "#                 of softmax is used later\n",
    "#             num_nodes: int, number of nodes/patches within the fully CRF\n",
    "#             use_crf: bool, use the CRF component or not\n",
    "#         \"\"\"\n",
    "#         super(ResNetCRF, self).__init__()\n",
    "#         base_model= torchvision.models.resnet50()\n",
    "#         num_ftrs = base_model.fc.in_features\n",
    "        \n",
    "#         self.feature_et = nn.Sequential(*list(base_model.children())[:-1])\n",
    "#         self.class_fc = nn.Linear(num_ftrs, num_classes)\n",
    "#         self.crf = CRF(num_nodes) if use_crf else None\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             x: 5D tensor with shape of\n",
    "#             [batch_size, grid_size, 3, crop_size, crop_size],\n",
    "#             where grid_size is the number of patches within a grid (e.g. 9 for\n",
    "#             a 3x3 grid); crop_size is 224 by default for ResNet input;\n",
    "#         Returns:\n",
    "#             logits, 2D tensor with shape of [batch_size, grid_size], the logit\n",
    "#             of each patch within the grid being tumor\n",
    "#         \"\"\"\n",
    "#         batch_size, grid_size, _, crop_size = x.shape[0:4]\n",
    "#         # flatten grid_size dimension and combine it into batch dimension\n",
    "#         x = x.view(-1, 3, crop_size, crop_size)\n",
    "#         x = self.feature_et(x)\n",
    "#         feats = x.view(x.size(0), -1)\n",
    "#         logits = self.class_fc(feats)\n",
    "\n",
    "#         # restore grid_size dimension for CRF\n",
    "#         feats = feats.view((batch_size, grid_size, -1))\n",
    "#         logits = logits.view((batch_size, grid_size, -1))\n",
    "#         if self.crf:\n",
    "#             logits = self.crf(feats, logits)\n",
    "\n",
    "# #         logits = torch.squeeze(logits)\n",
    "\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8235dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1, num_nodes=1,\n",
    "                 use_crf=True):\n",
    "        \"\"\"Constructs a ResNet model.\n",
    "        Args:\n",
    "            num_classes: int, since we are doing binary classification\n",
    "                (tumor vs normal), num_classes is set to 1 and sigmoid instead\n",
    "                of softmax is used later\n",
    "            num_nodes: int, number of nodes/patches within the fully CRF\n",
    "            use_crf: bool, use the CRF component or not\n",
    "        \"\"\"\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.crf = CRF(num_nodes) if use_crf else None\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 5D tensor with shape of\n",
    "            [batch_size, grid_size, 3, crop_size, crop_size],\n",
    "            where grid_size is the number of patches within a grid (e.g. 9 for\n",
    "            a 3x3 grid); crop_size is 224 by default for ResNet input;\n",
    "        Returns:\n",
    "            logits, 2D tensor with shape of [batch_size, grid_size], the logit\n",
    "            of each patch within the grid being tumor\n",
    "        \"\"\"\n",
    "        batch_size, grid_size, _, crop_size = x.shape[0:4]\n",
    "        # flatten grid_size dimension and combine it into batch dimension\n",
    "        x = x.view(-1, 3, crop_size, crop_size)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # feats means features, i.e. patch embeddings from ResNet\n",
    "        feats = x.view(x.size(0), -1)\n",
    "        logits = self.fc(feats)\n",
    "\n",
    "        # restore grid_size dimension for CRF\n",
    "        feats = feats.view((batch_size, grid_size, -1))\n",
    "        logits = logits.view((batch_size, grid_size, -1))\n",
    "\n",
    "        if self.crf:\n",
    "            logits = self.crf(feats, logits)\n",
    "\n",
    "        logits = torch.squeeze(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32ef0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(output, labels):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for i in range(output.size()[0]):\n",
    "        probs = output[i].sigmoid()\n",
    "        predicts = (probs >= 0.5).type(torch.cuda.FloatTensor)\n",
    "        for j in range(len(predicts)):\n",
    "            patch_pred = predicts[j].cpu().item()\n",
    "            patch_label = labels[i][j].cpu().item()\n",
    "            if patch_pred == patch_label == 0:\n",
    "                TN += 1\n",
    "            elif patch_pred == patch_label == 1:\n",
    "                TP += 1\n",
    "            elif patch_pred == 0 and patch_label == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    return TN, TP, FN, FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  6553 1573\n",
      "train:  5233 1268\n",
      "test:  1320 305\n",
      "number of training data 406\n",
      "number of testing data 101\n",
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fdb2f6008f46c9bf6fb14b6899c218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52138 49 5959 322\n",
      "Stage train\n",
      "Specificity:  0.9938619900876858\n",
      "Sensitivity:  0.008155792276964047\n",
      "Precision:  0.1320754716981132\n",
      "F1-Score:  0.01536290954695093\n",
      "Loss: 0.3358 Lr: 0.0002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782d4f36f4a14fc5b119bab43c0babea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ccd77bf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/congz3414050/HistoGCN/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/congz3414050/HistoGCN/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ccd77bf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/congz3414050/HistoGCN/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/congz3414050/HistoGCN/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65236 49 7405 322\n",
      "Stage val\n",
      "Specificity:  0.9950883187406572\n",
      "Sensitivity:  0.006573651730614435\n",
      "Precision:  0.1320754716981132\n",
      "F1-Score:  0.012523961661341851\n",
      "Loss: 0.3063 Lr: 0.0002\n",
      "===========End of Epoch 0=============\n",
      "Epoch 1/29\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7010fe245cd4adc8706710c79b93364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 16\n",
    "data_pth = '/home/congz3414050/HistoGCN/data/5X/Tumor_768/all_data.csv'\n",
    "model_save_path = '/home/congz3414050/HistoGCN/checkpoint/Scratch_Res50CRF_torch.pt'\n",
    "annotation_path = '/home/congz3414050/HistoGCN/data/Original/annotation'\n",
    "wsi_dataset = WSIDataset(data_pth, annotation_path)\n",
    "trainloader = wsi_dataset.Obtain_loader('Train', batch_size)\n",
    "testloader = wsi_dataset.Obtain_loader('Test', batch_size)\n",
    "\n",
    "# check readed data\n",
    "print('number of training data %d' % len(trainloader))\n",
    "print('number of testing data %d' % (len(testloader)))\n",
    "model = resnet50(num_classes=1, num_nodes=9)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "# for batch_data in trainloader:\n",
    "#     (img_flat, label_flat) = batch_data\n",
    "#     print('image size ',img_flat.size())\n",
    "#     print('label size ',label_flat.size())\n",
    "#     pred = model(img_flat)\n",
    "#     pred = pred.squeeze(-1)\n",
    "#     print(pred.size(), label_flat.size())\n",
    "#     loss = criterion(pred, label_flat)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     break\n",
    "\n",
    "since = time.time()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)  # , weight_decay=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "best_acc = 0.0\n",
    "best_loss = float('inf')\n",
    "best_f1 = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    dataloaders = {'train': trainloader, 'val': testloader}\n",
    "    batch_TP = 1\n",
    "    batch_TN = 1\n",
    "    batch_FP = 1\n",
    "    batch_FN = 1\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    stop_count = 0\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in tqdm(dataloaders[phase]):\n",
    "            (img_flat, label_flat) = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                pred = model(img_flat)\n",
    "                pred = pred.squeeze(-1)\n",
    "\n",
    "                loss = criterion(pred, label_flat)\n",
    "                TN, TP, FN, FP = metric(pred, label_flat)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            # statistics\n",
    "            running_loss += loss.item() * img_flat.size(0)\n",
    "            batch_TN += TN\n",
    "            batch_TP += TP\n",
    "            batch_FN += FN\n",
    "            batch_FP += FP\n",
    "            stop_count += 1\n",
    "#             if stop_count > 10:\n",
    "#                 break\n",
    "#             break\n",
    "        # epoch_f1 = metric(dataloaders[phase], graphloader, model, batch_size, use_graph=use_graph)\n",
    "        print(batch_TN, batch_TP, batch_FN, batch_FP)\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        Specificity = batch_TN / (batch_TN + batch_FP)\n",
    "        Sensitivity = batch_TP / (batch_FN + batch_TP)\n",
    "        Precision = batch_TP / (batch_TP + batch_FP)\n",
    "        F1_Score = 2 * (Precision * Sensitivity) / (Precision + Sensitivity)\n",
    "\n",
    "        print('Stage %s'%phase)\n",
    "        print('Specificity: ', Specificity)\n",
    "        print('Sensitivity: ', Sensitivity)\n",
    "        print('Precision: ', Precision)\n",
    "        print('F1-Score: ', F1_Score)\n",
    "        print('Loss: {:.4f} Lr: {}'.format(epoch_loss, optimizer.param_groups[0][\"lr\"]))\n",
    "\n",
    "        # deep copy the modela\n",
    "        if phase == 'val':\n",
    "            val_loss = epoch_loss\n",
    "            if F1_Score > best_f1:\n",
    "                best_f1 = F1_Score\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, model_save_path)\n",
    "            print('===========End of Epoch %d============='%epoch)\n",
    "        # break\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val f1: {:4f} at epoch {:d}'.format(best_f1, best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b600714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.rand(64,2)\n",
    "a = np.swapaxes(a,0,1)\n",
    "a = np.reshape(a, (2, 8, 8))\n",
    "a = np.expand_dims(a, axis=0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cd828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
